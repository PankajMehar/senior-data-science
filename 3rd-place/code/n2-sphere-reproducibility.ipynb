{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SPHERE Challenge: Activity Recognition with Multimodal Sensor Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very excited to share our approach to win third prize The SPHERE Challenge. It was organized by [DrivenData](http://www.drivendata.org), the [ECML-PKDD](http://www.ecmlpkdd2016.org) conference and the [AARP](http://www.aarp.org/aarp-foundation/) foundation. \n",
    "\n",
    "In this post, we walk you through steps to work with the provied data (https://www.drivendata.org/competitions/42/data/) to generate final submission.\n",
    "\n",
    "There are four main sections in this post: \n",
    "\n",
    "1. Requirements modules. \n",
    "2. Directory structure. \n",
    "3. Generate Submission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "- Python 2.7\n",
    "- These are the library versions we worked with to produce our results. (requirements.txt)\n",
    "- Hardware configuration:\n",
    "    + Ubuntu 14.04\n",
    "    + Memory: 16G\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory structure\n",
    "\n",
    "```\n",
    "├── README.md         \n",
    "├── input\n",
    "│   ├── public_data    <- The original data.\n",
    "│   │   ├── accelerometer_axes.json\n",
    "│   │   ├── access_point_names.json\n",
    "│   │   ├── annotations.json\n",
    "│   │   ├── pir_locations.json\n",
    "│   │   ├── rooms.json\n",
    "│   │   ├── sample_submission.csv\n",
    "│   │   ├── train\n",
    "│   │   │   ├── 00001\n",
    "│   │   │   ├── ...\n",
    "│   │   │   └── 00010\n",
    "│   │   ├── test\n",
    "│   │   │   ├── 00011\n",
    "│   │   │   ├── ...\n",
    "│   │   │   └── 00882\n",
    "│   │   ├── video_feature_names.json\n",
    "│   │   └── video_locations.json\n",
    "│\n",
    "├── sub               <- Submissions - predictions on test.\n",
    "│\n",
    "├── models             <- Trained models, predictions on train.\n",
    "│\n",
    "├── references         <- Explanatory materials.\n",
    "│\n",
    "│\n",
    "├── requirements.txt   <- The requirements file for reproducing.\n",
    "│\n",
    "├── src                <- Source code for use in this project.\n",
    "│   │\n",
    "│   ├── visualise_data.py <- Scripts to read raw data as sequence.\n",
    "│   │\n",
    "│   ├── feature_extraction_v3.py       <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v5.py       <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v7.py       <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v8.py       <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v9.py       <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v11.py      <- Scripts to turn raw data into features for modeling.\n",
    "│   ├── feature_extraction_v17.py      <- Scripts to turn raw data into features for modeling.\n",
    "│   │\n",
    "│   ├── knn_v5a.py  <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── rf_v13a.py  <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v5.py   <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v8a.py  <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v10a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v12a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v14a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v15a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v16a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v18a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v19a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v20a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v21a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v22a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v24a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── xgb_v25a.py <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── nn_v20.py   <- Scripts to train level 1 models and then use trained models to make predictions.\n",
    "│   ├── gen_esb_data_v20.py <- Scripts to prepare data for level 2 ensembling.\n",
    "│   │\n",
    "│   ├── sgd_esb_v20.py        <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── xgb_esb_v3.py         <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── xgb_esb_v4.py         <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── xgb_esb_v5.py         <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── xgb_esb_v7.py         <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── xgb_esb_v25.py        <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── nn_esb_v20.py         <- Scripts to train level 2 models and generate submission.\n",
    "│   ├── blend.py              <- Scripts to and generate final submission.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcut\n",
    "You can run the following cell to run all source codes to carry out feature engineering, model training, and submission generating. If you want to run it one by one, please proceed to the next cell 'Extracting Features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./src\n",
    "chmod u+x run_all.sh\n",
    "./run_all.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features\n",
    "\n",
    "In this cell, we will extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./src/\n",
    "python feature_extraction_v3.py\n",
    "python feature_extraction_v5.py    \n",
    "python feature_extraction_v7.py\n",
    "python feature_extraction_v8.py    \n",
    "python feature_extraction_v9.py\n",
    "python feature_extraction_v11.py\n",
    "python feature_extraction_v17.py  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls ./input/public_data/train/00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1 Model Training\n",
    "\n",
    "1. We do cross validation (fold = 5) and use those to predict for all train instances.\n",
    "2. We train model on full data, and use those to predict for all test instances. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./src/\n",
    "python knn_v5a.py  \n",
    "python rf_v13a.py                 \n",
    "python xgb_v5.py                                   \n",
    "python xgb_v8a.py\n",
    "python xgb_v10a.py                 \n",
    "python xgb_v12a.py\n",
    "python xgb_v14a.py                 \n",
    "python xgb_v15a.py\n",
    "python xgb_v16a.py                 \n",
    "python xgb_v18a.py\n",
    "python xgb_v19a.py                 \n",
    "python xgb_v20a.py\n",
    "python xgb_v21a.py                 \n",
    "python xgb_v22a.py\n",
    "python xgb_v24a.py                 \n",
    "python xgb_v25a.py\n",
    "python nn_v20.py  \n",
    "python gen_esb_data_v20.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Model Training\n",
    "\n",
    "We use train and test predictions from level 1 to stack features and train level 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./src/\n",
    "python xgb_esb_v3.py               \n",
    "python xgb_esb_v4.py\n",
    "python xgb_esb_v5.py               \n",
    "python xgb_esb_v7.py\n",
    "python xgb_esb_v25.py\n",
    "python sgd_esb_v20.py              \n",
    "python nn_esb_v20.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending\n",
    "We blend level 2 models to generate the final submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./src/\n",
    "python blend.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls ./sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
